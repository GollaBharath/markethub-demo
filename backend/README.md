# MarketHub Backend

TypeScript/Node.js backend service for the MarketHub e-commerce price tracking platform.

## ğŸ¯ Overview

This backend service provides RESTful APIs for:

- User authentication and authorization
- Multi-platform product scraping (Amazon, Flipkart, Meesho, Myntra, Ajio)
- Price history tracking and analytics
- Price alerts and notifications
- Smart product search with fuzzy matching
- Live deals management with automated scraping
- User tracklist management

## ğŸ› ï¸ Tech Stack

- **Runtime**: Node.js 18+
- **Framework**: Express.js
- **Language**: TypeScript
- **Database**: MongoDB with Mongoose ODM
- **Cache**: Redis
- **Queue**: RabbitMQ
- **Scraping**: Puppeteer, Playwright, Cheerio
- **Authentication**: JWT (JSON Web Tokens)
- **Scheduling**: node-cron

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/              # Configuration files
â”‚   â”‚   â”œâ”€â”€ database.ts      # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ redis.ts         # Redis connection
â”‚   â”‚   â””â”€â”€ rabbit.ts        # RabbitMQ connection
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/         # Request handlers
â”‚   â”‚   â”œâ”€â”€ authController.ts
â”‚   â”‚   â”œâ”€â”€ adminAuthController.ts
â”‚   â”‚   â”œâ”€â”€ dealController.ts
â”‚   â”‚   â”œâ”€â”€ scraperController.ts
â”‚   â”‚   â”œâ”€â”€ priceController.ts
â”‚   â”‚   â”œâ”€â”€ alertController.ts
â”‚   â”‚   â”œâ”€â”€ tracklistController.ts
â”‚   â”‚   â””â”€â”€ summaryController.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ middleware/          # Express middleware
â”‚   â”‚   â””â”€â”€ authMiddleware.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # Mongoose models
â”‚   â”‚   â”œâ”€â”€ User.ts
â”‚   â”‚   â”œâ”€â”€ Deal.ts
â”‚   â”‚   â”œâ”€â”€ PriceHistory.ts
â”‚   â”‚   â””â”€â”€ Alert.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/              # API routes
â”‚   â”‚   â”œâ”€â”€ authRoutes.ts
â”‚   â”‚   â”œâ”€â”€ adminAuthRoutes.ts
â”‚   â”‚   â”œâ”€â”€ dealRoutes.ts
â”‚   â”‚   â”œâ”€â”€ scraperRoutes.ts
â”‚   â”‚   â”œâ”€â”€ priceRoutes.ts
â”‚   â”‚   â”œâ”€â”€ alertRoutes.ts
â”‚   â”‚   â”œâ”€â”€ tracklistRoutes.ts
â”‚   â”‚   â””â”€â”€ summaryRoutes.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/            # Platform scrapers
â”‚   â”‚   â”œâ”€â”€ amazonScraper.ts
â”‚   â”‚   â”œâ”€â”€ flipkartScraper.ts
â”‚   â”‚   â”œâ”€â”€ meeshoScraper.ts
â”‚   â”‚   â”œâ”€â”€ myntraScraper.ts
â”‚   â”‚   â”œâ”€â”€ ajioScraper.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ jobs/                # Background jobs
â”‚   â”‚   â”œâ”€â”€ scrapeScheduler.ts
â”‚   â”‚   â””â”€â”€ dealsScheduler.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”‚   â”œâ”€â”€ productMatcher.ts
â”‚   â”‚   â”œâ”€â”€ recommendation.ts
â”‚   â”‚   â”œâ”€â”€ cleanupInvalidDeals.ts
â”‚   â”‚   â””â”€â”€ createAdmin.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ types/               # TypeScript definitions
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ bcryptjs.d.ts
â”‚   â”‚
â”‚   â””â”€â”€ server.ts            # Application entry point
â”‚
â”œâ”€â”€ dist/                    # Compiled JavaScript
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

## ğŸš€ Getting Started

### Prerequisites

Ensure you have the following installed:

- Node.js 18.x or higher
- MongoDB 6.x or higher
- Redis 7.x (optional but recommended)
- RabbitMQ 3.x (optional but recommended)

### Installation

1. **Install dependencies**

   ```bash
   npm install
   ```

2. **Configure environment**

   ```bash
   cp .env.example .env
   ```

   Edit `.env` with your configuration:

   ```env
   # Server
   PORT=5000
   NODE_ENV=development

   # Database
   MONGODB_URI=mongodb://localhost:27017/markethub

   # Authentication
   JWT_SECRET=your-super-secret-jwt-key-change-this-in-production

   # Redis (optional)
   REDIS_URL=redis://localhost:6379

   # RabbitMQ (optional)
   RABBITMQ_URL=amqp://localhost

   # Admin Credentials
   ADMIN_USERNAME=admin
   ADMIN_PASSWORD=admin123
   ```

3. **Start required services**

   ```bash
   # MongoDB
   mongod --dbpath=/path/to/data

   # Redis (optional)
   redis-server

   # RabbitMQ (optional)
   rabbitmq-server
   ```

4. **Run the development server**

   ```bash
   npm run dev
   ```

   The server will start on http://localhost:5000

### Production Build

```bash
# Build TypeScript to JavaScript
npm run build

# Start production server
npm start
```

## ğŸ“¡ API Overview

Base URL: `http://localhost:5000/api`

### Authentication Endpoints

- `POST /auth/register` - Register new user
- `POST /auth/login` - User login
- `POST /auth/admin` - Admin login

### Product Scraping

- `POST /scrape/amazon` - Scrape Amazon product
- `POST /scrape/flipkart` - Scrape Flipkart product
- `POST /scrape/meesho` - Scrape Meesho product
- `POST /scrape/myntra` - Scrape Myntra product
- `POST /scrape/ajio` - Scrape Ajio product

### Deals & Search

- `GET /deals/search` - Smart product search across platforms
- `GET /deals/live` - Get live deals from all platforms
- `POST /deals/scrape` - Add a deal manually
- `POST /deals/scrape-search` - Trigger live scraping for search query

### Price History

- `GET /prices/:productId` - Get price history for a product
- `GET /summary/:productId` - Get price summary and recommendations

### Alerts

- `POST /alerts` - Create price alert
- `GET /alerts` - Get user's price alerts

### Tracklist

- `POST /tracklist` - Add product to tracklist
- `GET /tracklist` - Get user's tracklist
- `DELETE /tracklist/:productId` - Remove from tracklist

See [API_DOCUMENTATION.md](./API_DOCUMENTATION.md) for complete API reference.

## ğŸ”§ Features

### Multi-Platform Scraping

- **Amazon India** - Full support with rating, reviews, images
- **Flipkart** - Product details with pricing
- **Meesho** - Budget products scraping
- **Myntra** - Fashion-focused scraping
- **Ajio** - Fashion and lifestyle products

### Smart Product Matching

- Fuzzy title matching using Jaccard similarity
- Normalization removes sizes, colors, common words
- Brand detection from product titles
- Category classification (electronics, fashion, etc.)
- 60%+ similarity threshold for grouping

### Automated Scraping

- **Deal Scheduler**: Runs every 6 hours
- **Initial Scrape**: 30 seconds after server start
- **Auto-Cleanup**: Expired deals removed via TTL indexes
- **Rate Limiting**: 3 requests/minute per platform

### Caching Strategy

- **Search Results**: 5-minute TTL in Redis
- **Cache Keys**: Include query + filters + sort
- **Auto-Invalidation**: When new deals added
- **Cache Indicator**: `fromCache` flag in responses

### Price Analytics

- Historical price tracking with timestamps
- Average, minimum, maximum price calculation
- Buy recommendations based on price trends
- Price drop percentage calculation

## ğŸ§ª Testing & Debugging

### Manual API Testing

```bash
# Test user registration
curl -X POST http://localhost:5000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test User",
    "email": "test@example.com",
    "password": "password123"
  }'

# Test product search
curl "http://localhost:5000/api/deals/search?query=iPhone%2015&sortBy=price_low"

# Test scraping (requires auth token)
curl -X POST http://localhost:5000/api/scrape/amazon \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://www.amazon.in/dp/PRODUCT_ID"}'
```

### Database Management

```bash
# Clean invalid deals from database
npm run cleanup:deals

# Access MongoDB shell
mongosh markethub

# Common MongoDB commands
db.deals.countDocuments()
db.deals.find({ platform: "amazon" })
db.users.find()
```

### Redis Cache Inspection

```bash
# Connect to Redis CLI
redis-cli

# Check cached searches
KEYS "search:*"

# View cache content
GET "search:query:iphone"

# Clear all cache
FLUSHALL
```

## ğŸ”’ Security

### Authentication

- JWT tokens with configurable expiration
- Password hashing using bcryptjs (10 rounds)
- Role-based access control (user, seller, admin)
- Protected routes with middleware

### Rate Limiting

- 3 requests/minute for scraping endpoints
- Prevents abuse and server overload
- Per-IP tracking

### Input Validation

- URL validation for scraping endpoints
- Price range validation for searches
- Query sanitization to prevent injection

### Anti-Bot Measures

- Puppeteer stealth mode
- Randomized user agents
- Request delays and throttling
- Headless browser detection evasion

## ğŸ”„ Background Jobs

### Deal Scheduler

- **Frequency**: Every 6 hours
- **Initial Run**: 30 seconds after server start
- **Function**: Scrapes all platforms for deals
- **Cleanup**: Removes expired deals (24-hour TTL)

### Price Update Scheduler

- **Frequency**: Daily at 3:00 AM
- **Function**: Updates tracked product prices
- **Notifications**: Triggers price alerts

## ğŸ“Š Database Schema

### User Model

```typescript
{
	name: string;
	email: string(unique, indexed);
	password: string(hashed);
	role: "user" | "seller" | "admin";
	createdAt: Date;
	updatedAt: Date;
}
```

### Deal Model

```typescript
{
  title: string (indexed)
  normalizedTitle: string (indexed)
  price: number
  originalPrice: number
  discount: number
  platform: string (indexed)
  url: string
  image: string
  rating: number
  reviews: number
  category: string
  brand: string
  expiresAt: Date (TTL index)
  createdAt: Date
}
```

### PriceHistory Model

```typescript
{
	productId: string(indexed);
	platform: string;
	price: number;
	timestamp: Date;
	title: string;
	url: string;
}
```

### Alert Model

```typescript
{
	userId: ObjectId(indexed);
	productId: string;
	targetPrice: number;
	currentPrice: number;
	isActive: boolean;
	createdAt: Date;
}
```

## ğŸ› Troubleshooting

### MongoDB Connection Issues

```bash
# Check if MongoDB is running
sudo systemctl status mongod

# Start MongoDB
sudo systemctl start mongod

# Check connection string in .env
MONGODB_URI=mongodb://localhost:27017/markethub
```

### Redis Connection Issues

```bash
# Check if Redis is running
redis-cli ping

# Start Redis
redis-server

# Use fallback if Redis unavailable (app continues without caching)
```

### Scraping Failures

- Check if target website structure changed
- Verify anti-bot measures aren't blocking requests
- Review puppeteer/playwright logs
- Test scraper selectors manually

### Port Already in Use

```bash
# Find process using port 5000
lsof -i :5000

# Kill the process
kill -9 <PID>
```

## ğŸ“ Development Guidelines

### Code Style

- Use TypeScript strict mode
- Follow ESLint configuration
- Use async/await over promises
- Implement proper error handling
- Add JSDoc comments for complex functions

### Git Workflow

- Create feature branches from `main`
- Use descriptive commit messages
- Test before pushing
- Create PRs for review

### Adding New Scrapers

1. Create scraper in `src/scrapers/newPlatform.ts`
2. Export from `src/scrapers/index.ts`
3. Add route in `src/routes/scraperRoutes.ts`
4. Update controller in `src/controllers/scraperController.ts`
5. Add rate limiting
6. Test thoroughly

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ“ Support

For issues, questions, or contributions:

- Open an issue on GitHub
- Email: support@markethub.com
